# -*- coding: utf-8 -*-
# """smart-vehicle-assistance-system.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1SJyslyPfMoOzHNKKIH3Cv2zGVFi7_9s8
# """

print("hello")

# # !wget --no-check-certificate https://cvrr-nas.ucsd.edu/LISA/Datasets/signDatabasePublicFramesOnly.zip
# """
# Setting work environment with dataset. If on Google colaboratory, we need to extract dataset stored in google drive,
# otherwise the dataset is already there.
# """
# try:
#     from google.colab import drive
#     print('Running on Google colab...')
#     drive.mount('/content/drive')
#     from zipfile import Zipfile
#     # /content/signDatabasePublicFramesOnly.zip
#     !cp '/content/drive/MyDrive/Colab Notebooks/DL-Project/signDatabasePublicFramesOnly.zip' dataset.zip

#     # with ZipFile('/content/drive/MyDrive/Colab Notebooks/DL-Project/signDatabasePublicFramesOnly.zip', 'r') as zip_ref:
#     #     zip_ref.extractall('test')
# except:
#     print('Running on local machine...')

# GET /test
print("hello")

# !ls
# !cp '/content/drive/MyDrive/Colab Notebooks/DL-Project/signDatabasePublicFramesOnly.zip' dataset.zip
# !ls

# !unzip dataset/*.zip

# ! ls
# ! cd ..
# ! cd aiua120214-0

import numpy as np
import os
import PIL
import PIL.Image
import tensorflow as tf
import shutil
from tensorflow import keras
from keras.models import Sequential #keras model architectures
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten,Dropout, BatchNormalization #types of layers
from keras.losses import mean_squared_error, huber, log_cosh  #built-in loss 
from tensorflow.python.keras.saving import hdf5_format  #used for saving models 
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard  #callbacks
from keras.models import model_from_json  #used for loading model architecture from json file
# import matplotlib.pyplot as plt
import h5py;
from keras.applications.resnet_v2 import ResNet50V2
from keras.models import Model
from keras.layers import Dense, Flatten, GlobalAveragePooling2D

print(tf.__version__)

import pathlib
import os.path
from os import path
import sys
print(sys.path)


def preprocessDataFiles():
  prefix = "dataset/lisa-dataset/"
  dataset_dirs = ["aiua120214-0","aiua120214-1","aiua120214-2","aiua120306-0","aiua120306-1","vid0","vid1","vid2","vid3"]
  for dataset_dir in dataset_dirs:
    dataset_dir = prefix + dataset_dir; 
    data_dir = pathlib.Path(dataset_dir).with_suffix('');
    print(data_dir);
    traffic_sign_files = list(data_dir.glob('*/*.png'));
    print(traffic_sign_files);

  destination_parent_folder = "dataset/train/"

  ts_set = os.listdir(destination_parent_folder);
  print(type(ts_set));
  for src_file in traffic_sign_files:
    # print(src_file);
    destn_filename = str(src_file).split("/")[4];
    sign = destn_filename.split("_")[0];
    destination_sign_folder = destination_parent_folder + sign;
    destn_path = destination_sign_folder + "/" + destn_filename;
    print("src sign: ", sign);
    if sign not in ts_set:
      os.mkdir(destination_sign_folder);
      ts_set.append(sign);
    print("src_path:", src_file)   
    print("destn_path:", destn_path)   
    shutil.copyfile(src_file, destn_path);

img_height = 180
img_width = 180
  
def processData():
  # import pathlib
  # import os.path
  # from os import path
  # import sys
  # print(sys.path)

  # # dataset_dir = "aiua120214-0/frameAnnotations-DataLog02142012_external_camera"
  
  # data_dir = pathlib.Path(dataset_dir).with_suffix('');
  # print(data_dir);
  # traffic_signs = list(data_dir.glob('*/*.png'))
  # image_count = len(traffic_signs)
  # print(image_count)
  # print(path.exists(dataset_dir))
  # PIL.Image.open(str(traffic_signs[0]))


  global total_img_classes;
  global class_names;
  train_dataset_dir = "dataset/train"
  batch_size = 32
  
  train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dataset_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size)

  val_ds = tf.keras.utils.image_dataset_from_directory(
    train_dataset_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size)

  class_names = train_ds.class_names
  print(class_names)


  # plt.figure(figsize=(10, 10))
  # for images, labels in train_ds.take(1):
  #   for i in range(9):
  #     ax = plt.subplot(3, 3, i + 1)
  #     plt.imshow(images[i].numpy().astype("uint8"))
  #     plt.title(class_names[labels[i]])
  #     plt.axis("off")

  for image_batch, labels_batch in train_ds:
    print(image_batch.shape)
    print(labels_batch.shape)
    break

  AUTOTUNE = tf.data.AUTOTUNE

  train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

  normalization_layer = keras.layers.Rescaling(1./255)

  normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
  image_batch, labels_batch = next(iter(normalized_ds))
  first_image = image_batch[0]
  # Notice the pixel values are now in `[0,1]`.
  print(np.min(first_image), np.max(first_image))
  total_img_classes = len(class_names)
  return train_ds, val_ds

def train_model(train_ds, val_ds, model):
  epochs=10
  model.compile(optimizer='adam',
                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])

  model.summary()

  history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs
  )

  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  epochs_range = range(epochs)

  # plt.figure(figsize=(8, 8))
  # plt.subplot(1, 2, 1)
  # plt.plot(epochs_range, acc, label='Training Accuracy')
  # plt.plot(epochs_range, val_acc, label='Validation Accuracy')
  # plt.legend(loc='lower right')
  # plt.title('Training and Validation Accuracy')

  # plt.subplot(1, 2, 2)
  # plt.plot(epochs_range, loss, label='Training Loss')
  # plt.plot(epochs_range, val_loss, label='Validation Loss')
  # plt.legend(loc='upper right')
  # plt.title('Training and Validation Loss')
  # plt.show()
  return;

# Save model
def save_model(model_path, model, name, description):
    # This function takes the prefix of the model_path and a name and description as input
    # and saves the architecture as a json file and weights as additional file.
    # The best model is already saved by the mcp_callback during the fit() call with extension *.mcp.hdf5
    
    # Step 1: serialize model architecture to *.json file
    model_json = model.to_json()
    with open(model_path+".json", "w") as json_file:
        json_file.write(model_json)

    #Step 2: now the model weights + additional attributes as *.additional
    with h5py.File(model_path+'.additional', mode='w') as f:
        hdf5_format.save_model_to_hdf5(model, f)
        f.attrs['name'] = name
        f.attrs['description'] = description


#load model
def load_model(model_path):
    # This function loads from the 3 files: *.json, *.additional, *.mcp.hdf5 located at the model_path prefix
    # and returns the best model, it's name and description
    
    mode = []
    name = 'NA'
    descripton = 'NA'
    with open(model_path+'.json', 'r') as json_file:
        loaded_model_json = json_file.read()
        model = model_from_json(loaded_model_json) #load the architecture
        model.load_weights(model_path+'.mcp.hdf5') #load the weights (from the ModelCheckPoint)
        
        with h5py.File(model_path+'.additional', mode='r') as f: #load the additional name/description info
            name = f.attrs['name']
            description = f.attrs['description']
    return [model, name, description]

def build_model1():
    return keras.Sequential([
      keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
      keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
      keras.layers.MaxPooling2D(),
      keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
      keras.layers.MaxPooling2D(),
      keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
      keras.layers.MaxPooling2D(),
      keras.layers.Flatten(),
      keras.layers.Dense(128, activation='relu'),
      keras.layers.Dense(total_img_classes)
    ]);
    
def build_model2():
  return keras.Sequential([
    keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
    keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
    keras.layers.MaxPooling2D(),
    keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
    keras.layers.MaxPooling2D(),
    keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
    keras.layers.MaxPooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(total_img_classes, activation='softmax')
  ]);
  
def build_model3():
  return keras.Sequential([
    keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
    keras.layers.Conv2D(32, 3, padding='valid', activation='relu'),
    keras.layers.MaxPooling2D(),
    keras.layers.Conv2D(64, 3, padding='valid', activation='relu'),
    keras.layers.MaxPooling2D(),
    keras.layers.Conv2D(128, 3, padding='valid', activation='relu'),
    keras.layers.MaxPooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dense(total_img_classes, activation='softmax')
  ]);

def test_model(model):
  # test_sign_path = "traffic_signs/test/stop_1330545935.avi_image1.png"
  # test_sign_path = "traffic_signs/test/speedLimit_1331865914.avi_image5.png"
  # test_sign_path = "traffic_signs/test/stop_1331866061.avi_image9.png"

  # test_sign_path ="aiua120214-1/frameAnnotations-DataLog02142012_001_external_camera.avi_annotations/signalAhead_1331866051.avi_image8.png"
  # test_sign_path="aiua120306-0/frameAnnotations-DataLog02142012_002_external_camera.avi_annotations/keepRight_1333393709.avi_image10.png"
  # sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)

  # test_paths = ["traffic_signs/test/stop_1330545935.avi_image1.png",
  #               "traffic_signs/test/speedLimit_1331865914.avi_image5.png",
  #               "traffic_signs/test/stop_1331866061.avi_image9.png",
  #               "aiua120306-0/frameAnnotations-DataLog02142012_002_external_camera.avi_annotations/keepRight_1333393709.avi_image10.png"]

  # test_dir = "dataset/lisa-dataset/aiua120306-0"
  test_dir="../public/test"
  data_dir = pathlib.Path(test_dir).with_suffix('');
  # print(data_dir);
  test_paths = list(data_dir.glob('*.png'))
  # print(test_paths);
  result_list = [];

  for test_sign_path in test_paths:
    result = {"img_path": "", "predictions": "", "score":0};
    
    print("-----", test_sign_path);
    img = keras.utils.load_img(
        test_sign_path, target_size=(img_height, img_width)
    )
    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) # Create a batch

    predictions = model.predict(img_array)
    score = tf.nn.softmax(predictions[0])

    message = "This image most likely belongs to {} with a {:.2f} percent confidence.".format(class_names[np.argmax(score)], 100 * np.max(score));
    # print(message);
    # print("\n\n\n")
    str_test_sign_path = str(test_sign_path)
    result["img_path"] = str_test_sign_path[9:len(str_test_sign_path)];
    result["prediction"] = str(class_names[np.argmax(score)]);
    result["score"]= str(100 * np.max(score));
    result_list.append(result);
  return result_list;
    
# print(tf.__version__)
# # preprocessDataFiles();
# train_ds, val_ds = processData();
# # print("total classes: ", total_img_classes);
# model1 = build_model1();
# train_model(train_ds, val_ds, model1);
# checkpoint_path = "dataset/saved_models/model1/cp.ckpt"
# checkpoint_dir = os.path.dirname(checkpoint_path)

# # Create a callback that saves the model's weights
# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
#                                                  save_weights_only=True,
#                                                  verbose=1)
# model1.save_weights(checkpoint_path.format(epoch=0))

# model1.load_weights(checkpoint_path)
# model_path = 'dataset/saved_models/model1.sav'
# save_model(model_path, model1, name="Model1", description="Model1");
# result_list = test_model(model1);

# for result in result_list:
#   print(result["img_path"]);
#   print(result["prediction"]);
#   print(result["score"]);
  
  
# model2 = build_model1();
# train(train_ds, val_ds, model1);

# !ls
# preprocessDataFiles();
# train_ds, val_ds = processData();
# model1 = build_model2();
# train_model(train_ds, val_ds, model1);


